{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CSCI316-week10\") \\\n",
    ".config(\"spark-master\", \"local\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "myManualSchema = StructType([\n",
    "    StructField(\"label\",LongType(),True),\n",
    "    StructField(\"ta1\",DoubleType(),True),\n",
    "    StructField(\"ta2\",DoubleType(),True),\n",
    "    StructField(\"ta3\",DoubleType(),True),\n",
    "    StructField(\"ta4\",DoubleType(),True),\n",
    "    StructField(\"ta5\",DoubleType(),True),\n",
    "    StructField(\"ta6\",DoubleType(),True),\n",
    "    StructField(\"ta7\",DoubleType(),True),\n",
    "    StructField(\"ta8\",DoubleType(),True),\n",
    "    StructField(\"ta9\",DoubleType(),True),\n",
    "    StructField(\"ta10\",DoubleType(),True),\n",
    "    StructField(\"ta11\",DoubleType(),True),\n",
    "    StructField(\"ta12\",DoubleType(),True),\n",
    "    StructField(\"t1\",DoubleType(),True),\n",
    "    StructField(\"t2\",DoubleType(),True),\n",
    "    StructField(\"t3\",DoubleType(),True),\n",
    "    StructField(\"t4\",DoubleType(),True),\n",
    "    StructField(\"t5\",DoubleType(),True),\n",
    "    StructField(\"t6\",DoubleType(),True),\n",
    "    StructField(\"t7\",DoubleType(),True),\n",
    "    StructField(\"t8\",DoubleType(),True),\n",
    "    StructField(\"t9\",DoubleType(),True),\n",
    "    StructField(\"t10\",DoubleType(),True),\n",
    "    StructField(\"t11\",DoubleType(),True),\n",
    "    StructField(\"t12\",DoubleType(),True),\n",
    "    StructField(\"t13\",DoubleType(),True),\n",
    "    StructField(\"t14\",DoubleType(),True),\n",
    "    StructField(\"t15\",DoubleType(),True),\n",
    "    StructField(\"t16\",DoubleType(),True),\n",
    "    StructField(\"t17\",DoubleType(),True),\n",
    "    StructField(\"t18\",DoubleType(),True),\n",
    "    StructField(\"t19\",DoubleType(),True),\n",
    "    StructField(\"t20\",DoubleType(),True),\n",
    "    StructField(\"t21\",DoubleType(),True),\n",
    "    StructField(\"t22\",DoubleType(),True),\n",
    "    StructField(\"t23\",DoubleType(),True),\n",
    "    StructField(\"t24\",DoubleType(),True),\n",
    "    StructField(\"t25\",DoubleType(),True),\n",
    "    StructField(\"t26\",DoubleType(),True),\n",
    "    StructField(\"t27\",DoubleType(),True),\n",
    "    StructField(\"t28\",DoubleType(),True),\n",
    "    StructField(\"t29\",DoubleType(),True),\n",
    "    StructField(\"t30\",DoubleType(),True),\n",
    "    StructField(\"t31\",DoubleType(),True),\n",
    "    StructField(\"t32\",DoubleType(),True),\n",
    "    StructField(\"t33\",DoubleType(),True),\n",
    "    StructField(\"t34\",DoubleType(),True),\n",
    "    StructField(\"t35\",DoubleType(),True),\n",
    "    StructField(\"t36\",DoubleType(),True),\n",
    "    StructField(\"t37\",DoubleType(),True),\n",
    "    StructField(\"t38\",DoubleType(),True),\n",
    "    StructField(\"t39\",DoubleType(),True),\n",
    "    StructField(\"t40\",DoubleType(),True),\n",
    "    StructField(\"t41\",DoubleType(),True),\n",
    "    StructField(\"t42\",DoubleType(),True),\n",
    "    StructField(\"t43\",DoubleType(),True),\n",
    "    StructField(\"t44\",DoubleType(),True),\n",
    "    StructField(\"t45\",DoubleType(),True),\n",
    "    StructField(\"t46\",DoubleType(),True),\n",
    "    StructField(\"t47\",DoubleType(),True),\n",
    "    StructField(\"t48\",DoubleType(),True),\n",
    "    StructField(\"t49\",DoubleType(),True),\n",
    "    StructField(\"t50\",DoubleType(),True),\n",
    "    StructField(\"t51\",DoubleType(),True),\n",
    "    StructField(\"t52\",DoubleType(),True),\n",
    "    StructField(\"t53\",DoubleType(),True),\n",
    "    StructField(\"t54\",DoubleType(),True),\n",
    "    StructField(\"t55\",DoubleType(),True),\n",
    "    StructField(\"t56\",DoubleType(),True),\n",
    "    StructField(\"t57\",DoubleType(),True),\n",
    "    StructField(\"t58\",DoubleType(),True),\n",
    "    StructField(\"t59\",DoubleType(),True),\n",
    "    StructField(\"t60\",DoubleType(),True),\n",
    "    StructField(\"t61\",DoubleType(),True),\n",
    "    StructField(\"t62\",DoubleType(),True),\n",
    "    StructField(\"t63\",DoubleType(),True),\n",
    "    StructField(\"t64\",DoubleType(),True),\n",
    "    StructField(\"t65\",DoubleType(),True),\n",
    "    StructField(\"t66\",DoubleType(),True),\n",
    "    StructField(\"t67\",DoubleType(),True),\n",
    "    StructField(\"t68\",DoubleType(),True),\n",
    "    StructField(\"t69\",DoubleType(),True),\n",
    "    StructField(\"t70\",DoubleType(),True),\n",
    "    StructField(\"t71\",DoubleType(),True),\n",
    "    StructField(\"t72\",DoubleType(),True),\n",
    "    StructField(\"t73\",DoubleType(),True),\n",
    "    StructField(\"t74\",DoubleType(),True),\n",
    "    StructField(\"t75\",DoubleType(),True),\n",
    "    StructField(\"t76\",DoubleType(),True),\n",
    "    StructField(\"t77\",DoubleType(),True),\n",
    "    StructField(\"t78\",DoubleType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "directory = \"/Users/will/Desktop\"\n",
    "dataT = spark.read.format(\"csv\").schema(myManualSchema).load(directory+\"/YearPredictionMSD.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "dataT_assembler = VectorAssembler(inputCols=['ta1','ta2','ta3','ta4','ta5','ta6','ta7',\\\n",
    "                               'ta8','ta9','ta10','ta11','ta12',\\\n",
    "                               't1','t2','t3','t4',\\\n",
    "                               't5','t6','t7','t8','t9','t10','t11','t12','t13','t14',\\\n",
    "                               't15','t16','t17','t18','t19','t20','t21','t22','t23',\\\n",
    "                               't24','t25','t26','t27','t28','t29','t30','t31','t32',\\\n",
    "                               't33','t34','t35','t36','t37','t38','t39','t40','t41',\\\n",
    "                               't42','t43','t44','t45','t46','t47','t48','t49','t50',\\\n",
    "                               't51','t52','t53','t54','t55','t56','t57','t58','t59',\\\n",
    "                               't60','t61','t62','t63','t64','t65','t66','t67','t68',\\\n",
    "                               't69','t70','t71','t72','t73','t74','t75','t76','t77','t78'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = dataT_assembler.transform(dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataT=dataT.select(['features','label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=5).fit(dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got the train data with the first 463715\n",
    "tr = model_dataT.limit(463715)\n",
    "\n",
    "# got the test data with the last 51630\n",
    "# Add an 'index' attribute as a standard for sorting\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "t0 = model_dataT.withColumn(\"index\",monotonically_increasing_id())\n",
    "#t0.count()\n",
    "# Convert to reverse\n",
    "t1 = t0.sort(\"index\",ascending = False)\n",
    "#t1.count()\n",
    "# select the first 51630 in the reverse (which means the last 51630 in original data)\n",
    "t2 = t1.limit(51630)\n",
    "#t2.count()\n",
    "#Conversion order as positive sequence\n",
    "t3 = t2.sort(\"index\",ascending = True)\n",
    "#t3.count()\n",
    "#Remove 'index' back to the original data composition.\n",
    "t4 = t3.drop('index')\n",
    "#t4.show()\n",
    "\n",
    "test = featureIndexer.transform(t4)\n",
    "train = featureIndexer.transform(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\",maxDepth = 10,maxBins = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer,dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|1991.9746835443038| 2007|[45.442,-30.74976...|\n",
      "| 2003.814880425155| 2003|[52.67814,-2.8891...|\n",
      "|1993.0542279411766| 2005|[45.74235,12.0229...|\n",
      "|2003.0085995085994| 2003|[52.55883,2.87222...|\n",
      "|2004.1737773152965| 2005|[51.34809,9.02702...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data = 95.0834\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 9.75107\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default split seed 666 mse = 99.7147\n",
    "# default dt Md8 = 94.634\n",
    "# default dt Md7 = 96.123\n",
    "# default dt Md9 = 93.5371\n",
    "# default dt Md10 = 93.1349\n",
    "# default dt Md11 = 94.2961\n",
    "\n",
    "# default Md10 = 94.3053 9.71109\n",
    "# default Md11 = 95.0834 9.75107"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
